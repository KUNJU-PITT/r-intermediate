---
title: "Data Manipulation and Visualisation in R"
author: "Mark Dunning"
date: '`r format(Sys.time(), "Last modified: %d %b %Y")`'
output: html_document
---
# [Course Home](http://bioinformatics-core-shared-training.github.io/r-intermediate/)

## Motivation

Spreadsheets are a common entry-point for many types of analyses. Whilst they are great for exploring / visualising data in an interactive and intuitive manner, they are not ideal for many production-level analyses.

- Tedious and time-consuming to repeatedly process multiple files
- Error-prone
- Unwieldy and difficult to deal with large amounts of data
- How can you (or someone else?) repeat what you did several months, or years down the line?

![](images/spreadsheet-full.png)

This course aims to translate how we think of data in spreadsheets to a series of operations that can be performed and chained together in R.


A data analysis can be broken-down into several stages. There is, however, no such thing as a typical analysis. Most datasets we will encounter will have their own issues and problems that need fixing. We will also need to spend a lot of time visualising our data in different ways in order to gain insights. For every figure or table presented in a paper, there may be tens or hundreds of exploratory analyses that were generated along the way. We will show how such exploratory analysis can be performed in R.

![](images/data-cycle.png)

(from Hadley Wickham's workshop at [useR2014](http://datascience.la/hadley-wickhams-dplyr-tutorial-at-user-2014-part-1/))

Unfortunately, in R there are many hundreds (thousands!) of functions for us to choose from to achieve our goals, and everyone will have their own set of favourites. The tools we will meet today help us to explore data in a consistent and "pipeline-able" manner. Collectively, these tools have been called part of the ***tidy-verse*** in R. A set of packages that you are likely to use in almost every analysis

- ggplot2, for data visualisation.
- dplyr, for data manipulation.
- tidyr, for data tidying.
- readr, for data import.
- purrr, for functional programming.
- tibble, for tibbles, a modern re-imagining of data frames.

To install this set of packages on your own machine, you can do:-

```{r eval=FALSE}
install.packages("devtools")
install_github("hadley/tidyverse")
```


Hadley also has these words of advice that we should bear in mind as we proceed through the course.

> Whenever you’re learning a new tool, for a long time you’re going to suck… But the good news is that is typical, that’s something that happens to everyone, and it’s only temporary.

## How does this differ from "Solving Biological Problems using R?"

- The [introductory course](http://cambiotraining.github.io/r-intro/) is designed to give you a taste of what R can do
    + we start from the very beginning, assuming you know nothing about programming
- Hopefully it gives you enough to read some data in, make a few basic plots
- It should allow you to access the majority of add-on packages
    + including Bioconductor ones
- When you try and seek help, most R users will be familiar with the "classic" techniques presented
- However, the data you try and analyse might not fit the data presented in the class....
    + you might be itching to try out new tools you have heard of; including ggplot2
- This course is designed to take you further with R
    + introduce more "cutting-edge" R
- Taking advantage of more recent innovations in the language
- Help you write more elegant solutions and code
- Hopefully appealing to those familiar with other languages


The [pre-course recap](https://rawgit.com/bioinformatics-core-shared-training/r-intermediate/master/0.r-recap.html) should hopefully cover most of what you need to know. Before starting the course proper, we will recap *data frames* and the *R markdown* reporting framework.

## The data frame

The data frame object in R allows us to work with "tabular" data, like we might be used to dealing with in Excel, where our data can be thought of having rows and columns. The values in each column have to all be of the same type (i.e. all numbers or all text).

![](https://upload.wikimedia.org/wikipedia/commons/thumb/7/78/Petal-sepal.jpg/226px-Petal-sepal.jpg)

The `iris` data frame is a [classic dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set) that is built into R. To load these data, we use the `data` function with the name `iris` (notice no quotation marks) in brackets. The data frame can then be printed to screen by typing it's name (`iris`).

N.B. As we will see later, we tend to read datasets into R using `read.csv`, `read.delim` or similar functions.

```{r}
data(iris)
```

The `View` function will create a tab in RStudio that we can use to browse the data.

```{r eval=FALSE}
View(iris)
```

A commonly-used function is `head` which will print the first six rows to the screen, otherwise R will attempt to show the entire object (very annoying for large objects!).
```{r}
head(iris)
```

We can notice that there are `r nrow(iris)` rows and `r ncol(iris)` columns. There is also a function in R, `dim`, that will print the dimensions for us. The `colnames` function will also print the names of the columns.

```{r}
dim(iris)
colnames(iris)
```

Data for a particular column can be accessed using what is known as the `$` operator. The result is a *vector*

```{r eval=FALSE}
iris$Sepal.Length
iris$Species
```

Here, `iris$Species` is a new type of object in R. It is an example of a *factor*, which is a type of object used frequently in data analysis. Rather than being merely a character string, the vector has a set of levels; **`r levels(iris$Species)`**. This allows us to perform various analyses that treat the values as belonging to different categories. For example, we might look to compare the distribution of length, width of different species and perform statistical testing. Having our data as factors aids such analyses.

The `summary` function is a versatile function to summarise an object. For this dataset, it reports the distribution of values in the first four columns, and a summary of the *categories* in the final column.

```{r}
summary(iris)
```

We will explore plotting in much more detail later on the course. R provides a wide-variety of [plotting options](http://www.statmethods.net/graphs/index.html) as part of the *base* distribution. Without going into too much detail, the following will create a boxplot of the values in `Sepal.Length` column categorised into the different values of `Species`. Such a plot allows us to look for differences in mean between different groups, and also assess the variability of the data.

```{r}
boxplot(iris$Sepal.Length~iris$Species)
```

Sometimes you may see this written as:

```{r}
boxplot(Sepal.Length~Species,data=iris)
```

An *analysis of variance* (ANOVA) analysis can also tell us if the differences between the groups are statistically significant

```{r}
mod <- aov(iris$Petal.Length~iris$Species)
anova(mod)
```


## How can R enable Reproducible Research?

![](images/rep-research-nyt.png)

Two Biostatisticians (later termed '*Forensic Bioinformaticians*') from M.D. Anderson used R extensively during their re-analysis and investigation of a Clinical Prognostication paper from Duke. The subsequent [scandal](https://www.youtube.com/watch?v=W5sZTNPMQRM) put Reproducible Research at the forefront of everyone's mind.

Keith Baggerly's talk on the subject is high-recommended.

<iframe width="420" height="315" src="https://www.youtube.com/embed/7gYIs7uYbMo" frameborder="0" allowfullscreen></iframe>



Within RStudio we can write *markdown* documents, which are a mix of R code and text. The markdown file can be used as a template to generated PDF, HTML, or even Word documents. The clever bit is that all R code in the template can be execute and the results displayed (tables, graphics etc) along with the code. The compiled document can be passed to your collaborators and they should be able to generate the same results. Alternatively, you can choose to hide the code if your PI just wants to see the results, and not necessarily what packages, parameters you used. Long-term R users may have heard of *Sweave*. Markdown is the same concept, but an easier to write (and read) syntax

Markdown can also generate presentations and courses. Indeed, all the [materials for this course](https://github.com/cambiotraining/r-intermediate) were written in markdown.



![](images/markdown-annotated.png)

1. Header information
2. Section heading
3. Plain text
4. R code to be run
5. Plain text
6. R code to be run




Each line of R code can be executed in the R console by placing the cursor on the line and pressing `CTRL + ENTER`. You can also highlight multiple lines of code. NB. You do not need to highlight to the backtick (`\``) symbols. 

Hitting the ***Knit*** button (*) will run all R code in order and (providing there are no errors!) you will get a PDF or HTML document. The resultant document will contain all the plain text you wrote, the R code, and any outputs (including graphs, tables etc) that R produced. You can then distribute this document to have a reproducible account of your analysis.

## How to use the template

- Change your name, add a title and date in the header section
- Add notes, explanations of code etc in the white space between code chunks. You can add new lines with `ENTER`. Clicking the `?` next to the `Knit HTML` button will give more information about how to format this text. You can introduce **bold** and *italics* for example.
- Some code chunks are left blank. These are for you to write the R code required to answer the questions
- You can try to knit the document at any point to see how it looks


## A Short Analysis Example

- Open the file `iris.Rmd`
    + this contains the code we have just looked at to load and visualise the `iris` dataset
    + change the header information to contain your name and the date
    + compile the document by pressing the ***Knit HTML*** button. This should produce a file called `iris.html`
    + modify the Rmd file so that the boxplot of the `Petal.Length` variable is produced, rather than `Sepal.Length`
    
